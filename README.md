# sign-language-recognition
Group Member:
  Yu Hou
  Yuhan Shao
  Zuer Wang
  
  
### About the project
Sign language is a crucial technique for bridging the communication gap between hearing-impaired and normal persons. In order to communicate with hearing-impaired person better, we built a distributed sign-language recognition systems to seek intelligent solutions for sign language classifications and help people to understand the meaning of each gesture. This paper aim to provide a sign-language recognition system to predict sign language with better accuracy and in faster speed. To implement the hand sign-language, we used ASL Alphabet as the database, which is an image data set for alphabets in American Sign Language and we ran Naive Bayes model on the training dataset to predict the sign-language of testing pictures. Moreover, we implement this system on the mobile Spark platform. In order to emulate the mobile environment and validate the feasibility of running Spark applications on mobile devices, we configured different network settings and discovered the effects of each traffic condition on the Job\'s execution time. The result of system is very encouraging with an average accuracy of over $92.857\%$ in a faster way.

## Contact

If you have discovered a bug in the build software or want to report an error in
the library, please create a new
[Issue](https://github.com/YunesHou/sign-language-recognition/issues) on our github page.